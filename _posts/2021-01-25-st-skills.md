---
layout: post
title: Useful Skills
categories: Skills
excerpt: Commands, Tools
status: visible
---

# tmux
终端复用器  窗口管理和会话管理
https://www.hamvocke.com/blog/a-quick-and-easy-guide-to-tmux/
(这个人的博客很酷)

0. tmux 打开一个会话
1. tmux ls 列出所有会话
2. tmux attach -t 0 连接到0号会话/终端窗口（session）
3. ctrl + b d detach一个会话
4. C-b % 水平分出一个pane窗格
5. C-b " 垂直分出一个窗格
6. C-b arrow key 窗格之间移动
7. exit退出窗格/窗口
8. C-b c 创建新的window C-b p, C-b n 切换前后窗口
9. tmux new -s database 创建会话的同时给会话起个名字
10. tmux rename-session -t 0 database 给已经存在的会话重命名
11. C-b ? 查看可用命令
12. C-b , 重命名窗口
13. tmux是一个服务器-客户端结构
14. C-b : 输入指令 source ~/tmux.conf, set mouse on
15. C-r :搜索历史命令
16. 按住shift进行复制粘贴

# Linux 命令
1. tee: 将标准输入，输出到文件 类似于 >
2. ls只列出部分目录或是文件: ls | head -n
3. zip -r train.zip train/
4. unzip train.zip

# slurm
## srun 参数
-n16 作业总的进程数
-gres 单个节点使用的GPU个数
--ntasks-per-node 单个节点最多的进程个数。每个进程占一个GPU，应该和-gres保持一致
Slurm根据总进程数和--ntasks-per-node来决定分配多少个节点，然后根据-gres决定每个节点分配多少个GPU

## 概念区分
1. group/world: 一组进程
2. world_size: 进程数
3. rank: 每个进程的独特id
https://discuss.pytorch.org/t/what-is-the-difference-between-rank-and-local-rank/61940
4. local_rank: the rank of the process on the local machine.
5. rank: the rank of the process in the network.
To illustrate that, let;s say you have 2 nodes (machines) with 2 GPU each, you will have a total of 4 processes (p1…p4):

            |    Node1  |   Node2    |
____________| p1 |  p2  |  p3  |  p4 |
local_rank  | 0  |   1  |  0   |   1 |
rank        | 0  |   1  |  2   |   4 |

## Pytorch多机多卡分布式训练
https://zhuanlan.zhihu.com/p/68717029
和dataparallel不同，dataparallel需要将batchsize设置成n倍的单卡batchsize。
而distributedsampler使用的情况下，batchsize设置与单卡设置相同。

这里有几个新的参数：world size, rank, local rank, rank。
world size指进程总数，在这里就是我们使用的卡数；rank指进程序号，local_rank指本地序号，
两者的区别在于前者用于进程间通讯，后者用于本地设备分配。这个时候真正麻烦的地方来了：

# Slurm commands
1. sinfo
2. squeue
3. squeue -p partition_name
4. squeue -u user_name
4. scontrol show job xxxx
5. swatch -l
5. swatch -n nodelist nv
6. scancel xxxx

# Jupyter Notebook
https://www.cnblogs.com/thousfeet/p/10647102.html
参考链接 不用配置ssh

1. 先查看服务器是否已有notebook配置文件，linux下的路径一般是“/home/USERNAME/.jupyter/jupyter_notebook_config.py”。如果没有进行过配置，默认是没有这个文件的，需要自己生成：
jupyter notebook --generate-config
生成配置文件
这行代码会在当前路径下生成一个.jupyter文件夹，并且文件夹中含有配置文件jupyter_notebook_config.py

2. notebook5.0以上的版本，需要运行一行命令 jupyter notebook password ，会让你填写密码和确认密码，并且生成含有密码的hash的jupyter_notebook_config.json在配置文件夹下。

3. 编辑 .jupyter 文件夹下的 jupyter_notebook_config.py，按照注释说明加入以下这几行代码

4. 这时候在本机浏览器键入https://xx.xx.xx.xx:9999(服务器ip）就可以访问了。

# oh my zsh
Oh My Zsh is a delightful, open source, community-driven framework for managing your Zsh configuration.

1. autojump

# filezilla
FileZilla is a free software, cross-platform FTP application, consisting of FileZilla Client and FileZilla Server.


# Dataset, Datasampler, Dataloader
https://www.cnblogs.com/marsggbo/p/11308889.html


看到这不难猜出collate_fn的作用就是将一个batch的数据进行合并操作。默认的collate_fn是将img和label分别合并成imgs和labels，所以如果你的__getitem__方法只是返回 img, label,那么你可以使用默认的collate_fn方法，但是如果你每次读取的数据有img, box, label等等，那么你就需要自定义collate_fn来将对应的数据合并成一个batch数据，这样方便后续的训练步骤。

上面三个方法是最基本的，其中__getitem__是最主要的方法，它规定了如何读取数据。但是它又不同于一般的方法，因为它是python built-in方法，其主要作用是能让该类可以像list一样通过索引值对数据进行访问。假如你定义好了一个dataset，那么你可以直接通过dataset[0]来访问第一个数据。在此之前我一直没弄清楚__getitem__是什么作用，所以一直不知道该怎么进入到这个函数进行调试。现在如果你想对__getitem__方法进行调试，你可以写一个for循环遍历dataset来进行调试了，而不用构建dataloader等一大堆东西了，建议学会使用ipdb这个库，非常实用！！！以后有时间再写一篇ipdb的使用教程。另外，其实我们通过最前面的Dataloader的__next__函数可以看到DataLoader对数据的读取其实就是用了for循环来遍历数据

<pre>
dataloader
->
datasampler -> indices
->
dataset -> data
</pre>

# 图形界面

http://bicmr.pku.edu.cn/~wenzw/pages/gui.html
http://bicmr.pku.edu.cn/~wenzw/pages/cheatsheet.html

# conda
conda install -c 表示channel
-c pytorch 从PyTorch的源而不是conda的源
